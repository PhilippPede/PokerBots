{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.optimize import linprog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful websites\n",
    "\n",
    "<b>Explain how to find NE with LP</b><br>\n",
    "https://cbom.atozmath.com/example/CBOM/GameTheory.aspx?he=e&q=lpp\n",
    "\n",
    "<b>NE / LP solver</b><br>\n",
    "https://linprog.com/en/main-simplex-method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some play-around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3, -2],\n",
       "       [-1,  0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payoff_me = np.array([[3,-2], [-1,0]])\n",
    "payoff_opp = np.array([[-3,2], [1,0]])\n",
    "\n",
    "payoff_me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 1],\n",
       "       [2, 3]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first make the payoff matrix >0 everywhere\n",
    "# linear affine transformations (ax+b) are the only ones allowed\n",
    "\n",
    "minVal = payoff_me.min()\n",
    "\n",
    "M_me = payoff_me - minVal + 1\n",
    "M_me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some notes on scipy linprog implementation\n",
    "\n",
    "https://stackoverflow.com/questions/45873783/python-linprog-minimization-simplex-method\n",
    "\n",
    "Key points:\n",
    "* expects the problem to be formulated as a $minimization$ of the objective function\n",
    "* expects the constraints to be formulated as $less$ (or equal). <br>\n",
    "Therefore, if a constraint is formulated as >=, flip the corresponding signs in A and b\n",
    "\n",
    "\n",
    "How to use LP to solve for NE: <br>\n",
    "http://www.universalteacherpublications.com/univ/ebooks/or/Ch9/gamelp.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization successful\n",
      "    Optimal value: 0.3750000028835264\n",
      "    X: [0.0625 0.3125]\n",
      "\n",
      "Optimal strategy for P1: 0.166667 0.833333\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/45873783/python-linprog-minimization-simplex-method\n",
    "A = np.array([[-6,-2], [-1, -3]])\n",
    "b = np.array([-1,-1])\n",
    "c = np.array([1,1])\n",
    "\n",
    "res = linprog(c, A_ub=A, b_ub=b, bounds=(0, 1))\n",
    "if res.status == 0:\n",
    "    print('Optimization successful')\n",
    "    print('    Optimal value:', res.fun)\n",
    "    print('    X:', res.x)\n",
    "\n",
    "print()\n",
    "print(\"Optimal strategy for P1: {:.6f} {:.6f}\".format(res.x[0]/res.fun, res.x[1]/res.fun))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "payoff_me = np.array([[3,-2], [-1,0]])\n",
    "payoff_opp = np.array([[-3,2], [1,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization successful\n",
      "    Optimal value: 0.3750000028835264\n",
      "    X: [0.0625 0.3125]\n",
      "\n",
      "Optimal strategy for P1: 0.166667 0.833333\n"
     ]
    }
   ],
   "source": [
    "# coefficients for objective function\n",
    "c = np.array([1,1])\n",
    "\n",
    "# constraint formulation (as minimization)\n",
    "minVal = payoff_me.min()\n",
    "M_me = payoff_me - minVal + 1\n",
    "A = (-1) * M_me.T\n",
    "b = np.array([-1,-1])\n",
    "\n",
    "res = linprog(c, A_ub=A, b_ub=b, bounds=(0, 1))\n",
    "if res.status == 0:\n",
    "    print('Optimization successful')\n",
    "    print('    Optimal value:', res.fun)\n",
    "    print('    X:', res.x)\n",
    "\n",
    "print()\n",
    "print(\"Optimal strategy for P1: {:.6f} {:.6f}\".format(res.x[0]/res.fun, res.x[1]/res.fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization successful\n",
      "    Optimal value: 0.23076923083867107\n",
      "    X: [0.07692308 0.15384615]\n",
      "\n",
      "Optimal strategy for P1: 0.333333 0.666667\n"
     ]
    }
   ],
   "source": [
    "# coefficients for objective function\n",
    "c = np.array([1,1])\n",
    "\n",
    "# constraint formulation (as minimization)\n",
    "#minVal = payoff_opp.min()\n",
    "#M_opp = payoff_opp - minVal + 1\n",
    "#A = (-1) * M_opp.T\n",
    "A = np.array([[1,6],[5,4]])*(-1)\n",
    "b = np.array([-1,-1])\n",
    "\n",
    "res = linprog(c, A_ub=A, b_ub=b, bounds=(0, 1))\n",
    "if res.status == 0:\n",
    "    print('Optimization successful')\n",
    "    print('    Optimal value:', res.fun)\n",
    "    print('    X:', res.x)\n",
    "\n",
    "print()\n",
    "print(\"Optimal strategy for P1: {:.6f} {:.6f}\".format(res.x[0]/res.fun, res.x[1]/res.fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_NashEquilibrium(mtx_payoff, player):\n",
    "    \"\"\"\n",
    "    find the NashEquilibrium based on the Normal represenation of the problem\n",
    "        use linear programming approach to maximise value from game for player\n",
    "            basic idea: for all pure strategies of opponent, find your own strategy that maximises value\n",
    "        \n",
    "        use scipy to solve this, which has few technical details\n",
    "            1) constraints need to be expressed as less/greater than\n",
    "                in the straightforward derivation of LP: those are expressed as >=\n",
    "            2) depending on whether we solve for p1 or p2, need to handle payOff matrix differently\n",
    "            3) ensure that all values in payoff matrix are positive (for LP formulation)\n",
    "                note that any affine linear transformation (ax+b) applied to payoff matrix leaves NE intact\n",
    "                ==> we can just add minValue+1 as that transformation\n",
    "    \n",
    "    mtx_payoff ... payoff matrix:\n",
    "        player1 actions: as rows\n",
    "        player2 actions: as cols\n",
    "        \n",
    "    player ... either 1 or 2\n",
    "    \"\"\"\n",
    "    \n",
    "    # linear transformation: make m_ij > 0\n",
    "    minVal = mtx_payoff.min()\n",
    "    mtx_M = mtx_payoff - minVal + 1\n",
    "\n",
    "    # construct matrix containing constraints (formulated as <=)\n",
    "    if player == 1:\n",
    "        A = mtx_M.T * (-1)\n",
    "    elif player == 2:\n",
    "        A = mtx_M * (-1)\n",
    "    else:\n",
    "        raise ValueError(f\"Player must be 1 or 2, but got {player}\")\n",
    "        \n",
    "    # construct vector with constraint-values\n",
    "    #  since we normalise by value, this is just a list of 1s\n",
    "    #  because minimise rather than maximise --> *(-1)\n",
    "    b = np.ones((1, A.shape[1])) * (-1)\n",
    "    \n",
    "    # coefficients for objective function\n",
    "    #  by formulation as LP, where we normalise by value --> automatically a minimization\n",
    "    c = np.ones((1, A.shape[1]))\n",
    "    \n",
    "    # solve the LP\n",
    "    res_LP = linprog(c, A_ub=A, b_ub=b, bounds=(0, 1))\n",
    "    if res_LP.status == 0:\n",
    "        #print('Optimization successful')\n",
    "        #print('    Optimal value:', res.fun)\n",
    "        #print('    X:', res.x)\n",
    "        \n",
    "        # re-construct probabilities for each pure player strategy\n",
    "        arr_prob = res_LP.x / res_LP.fun\n",
    "        return arr_prob\n",
    "    \n",
    "    else:\n",
    "        #print(\"Optimization failed\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy for player 1:  [0.16666667 0.83333333]\n",
      "Strategy for player 2:  [0.33333333 0.66666667]\n"
     ]
    }
   ],
   "source": [
    "payoff_p1 = np.array([[3,-2], [-1,0]])\n",
    "payoff_p2 = np.array([[-3,2], [1,0]])\n",
    "\n",
    "strategy_p1 = find_NashEquilibrium(mtx_payoff=payoff_p1, player=1)\n",
    "strategy_p2 = find_NashEquilibrium(mtx_payoff=payoff_p2, player=2)\n",
    "\n",
    "print(\"Strategy for player 1: \", strategy_p1)\n",
    "print(\"Strategy for player 2: \", strategy_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy for player 1:  [1.31682645e-12 1.00000000e+00]\n",
      "Strategy for player 2:  [1.31682645e-12 1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# Stag Hunt\n",
    "payoff_p1 = np.array([[4,1], [3,2]])\n",
    "payoff_p2 = np.array([[4,3], [1,2]])\n",
    "\n",
    "strategy_p1 = find_NashEquilibrium(mtx_payoff=payoff_p1, player=1)\n",
    "strategy_p2 = find_NashEquilibrium(mtx_payoff=payoff_p2, player=2)\n",
    "\n",
    "print(\"Strategy for player 1: \", strategy_p1)\n",
    "print(\"Strategy for player 2: \", strategy_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy for player 1:  [2.5654097e-12 1.0000000e+00]\n",
      "Strategy for player 2:  [2.5654097e-12 1.0000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# Prisoners dilemma\n",
    "payoff_p1 = np.array([[2,0], [3,1]])\n",
    "payoff_p2 = np.array([[2,3], [0,1]])\n",
    "\n",
    "strategy_p1 = find_NashEquilibrium(mtx_payoff=payoff_p1, player=1)\n",
    "strategy_p2 = find_NashEquilibrium(mtx_payoff=payoff_p2, player=2)\n",
    "\n",
    "print(\"Strategy for player 1: \", strategy_p1)\n",
    "print(\"Strategy for player 2: \", strategy_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy for player 1:  [0.33333333 0.33333333 0.33333333]\n",
      "Strategy for player 2:  [0.33333333 0.33333333 0.33333333]\n"
     ]
    }
   ],
   "source": [
    "# Rock Paper Scissor\n",
    "payoff_p1 = np.array([[0,0,1], [1,0,0], [0,1,0]])\n",
    "payoff_p2 = np.array([[0,1,0], [0,0,1], [1,0,0]]) # equivalent to p1.T\n",
    "\n",
    "strategy_p1 = find_NashEquilibrium(mtx_payoff=payoff_p1, player=1)\n",
    "strategy_p2 = find_NashEquilibrium(mtx_payoff=payoff_p2, player=2)\n",
    "\n",
    "print(\"Strategy for player 1: \", strategy_p1)\n",
    "print(\"Strategy for player 2: \", strategy_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy for player 1:  [0.2 0.2 0.2 0.2 0.2]\n",
      "Strategy for player 2:  [0.2 0.2 0.2 0.2 0.2]\n"
     ]
    }
   ],
   "source": [
    "# Rock Paper Scissor Lizard Spock\n",
    "payoff_p1 = np.array([[0,0,1,1,0], \n",
    "                      [1,0,0,0,1], \n",
    "                      [0,1,0,1,0],\n",
    "                      [0,1,0,0,1],\n",
    "                      [1,0,1,0,0]])\n",
    "\n",
    "payoff_p2 = payoff_p1.T\n",
    "\n",
    "strategy_p1 = find_NashEquilibrium(mtx_payoff=payoff_p1, player=1)\n",
    "strategy_p2 = find_NashEquilibrium(mtx_payoff=payoff_p2, player=2)\n",
    "\n",
    "print(\"Strategy for player 1: \", strategy_p1)\n",
    "print(\"Strategy for player 2: \", strategy_p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time the speed for finding the Nash equilibrium\n",
    "\n",
    "Creating the payoff matrix takes time, do that separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrixSize = 2048\n",
    "\n",
    "minVal=-10\n",
    "maxVal=10\n",
    "\n",
    "# Random payoff matrix\n",
    "payoff_p1 = np.round(np.random.rand(matrixSize,matrixSize) * (maxVal-minVal) + minVal)\n",
    "#payoff_p2 = (-1)*payoff_p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "CPU times: user 17min 48s, sys: 1min 22s, total: 19min 11s\n",
      "Wall time: 7min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "strategy_p1 = find_NashEquilibrium(mtx_payoff=payoff_p1, player=1)\n",
    "#strategy_p2 = find_NashEquilibrium(mtx_payoff=payoff_p2, player=2)\n",
    "\n",
    "print(np.sum(strategy_p1))\n",
    "#print(\"Strategy for player 1: \", strategy_p1)\n",
    "#print(\"Strategy for player 2: \", strategy_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cpuTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>4.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>23.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>143.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>469.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cpuTime\n",
       "2       0.021\n",
       "4       0.032\n",
       "8       0.029\n",
       "16      0.039\n",
       "32      0.371\n",
       "64      0.578\n",
       "128     1.220\n",
       "256     4.220\n",
       "512    23.300\n",
       "1024  143.000\n",
       "2048  469.000"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cpuTime = pd.DataFrame(\n",
    "    index=[2,4,8,16,32,64,128,256,512,1024, 2048],\n",
    "    data={\"cpuTime\": [0.021, 0.032, 0.029, 0.039, 0.371, 0.578, 1.22, 4.22, 23.3, 2*60+23, 7*60+49]})\n",
    "df_cpuTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cpuTime.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
